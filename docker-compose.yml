x-ctfd-base: &ctfd-base
  build: /opt/CTFd
  platform: linux/amd64
  user: root
  entrypoint: ""

x-ctfd-env: &ctfd-env
  DATABASE_URL: postgresql+psycopg2://${DB_USER}:${DB_PASS}@pgbouncer:5432/${DB_NAME}
  REDIS_URL: redis://cache:6379
  DOJO_HOST: ${DOJO_HOST}
  WORKSPACE_HOST: ${WORKSPACE_HOST}
  WORKSPACE_SECRET: ${WORKSPACE_SECRET}
  HOST_DATA_PATH: /data
  MAIL_SERVER: ${MAIL_SERVER}
  MAIL_PORT: ${MAIL_PORT}
  MAIL_USERNAME: ${MAIL_USERNAME}
  MAIL_PASSWORD: ${MAIL_PASSWORD}
  MAIL_ADDRESS: ${MAIL_ADDRESS}
  DISCORD_CLIENT_ID: ${DISCORD_CLIENT_ID}
  DISCORD_CLIENT_SECRET: ${DISCORD_CLIENT_SECRET}
  DISCORD_BOT_TOKEN: ${DISCORD_BOT_TOKEN}
  DISCORD_GUILD_ID: ${DISCORD_GUILD_ID}
  INTERNET_FOR_ALL: ${INTERNET_FOR_ALL}
  MAC_HOSTNAME: ${MAC_HOSTNAME}
  MAC_USERNAME: ${MAC_USERNAME}
  SSH_PIPER_API_TOKEN: ${SSH_PIPER_API_TOKEN}
  SSH_PIPER_BOOTSTRAP_DOJO: ${SSH_PIPER_BOOTSTRAP_DOJO}
  SSH_PIPER_BOOTSTRAP_DOJO_NAME: ${SSH_PIPER_BOOTSTRAP_DOJO_NAME}
  SSH_PIPER_UPSTREAM_HOST: ${SSH_PIPER_UPSTREAM_HOST}
  SSH_PIPER_UPSTREAM_PORT: ${SSH_PIPER_UPSTREAM_PORT}

x-ctfd-volumes: &ctfd-volumes
  - /data/dojos:/var/dojos
  - /data/workspace_nodes.json:/var/workspace_nodes.json:ro
  - ./user_firewall.allowed:/var/user_firewall.allowed:ro
  - /etc/docker/seccomp.json:/etc/docker/seccomp.json:ro
  - /var/run/docker.sock:/var/run/docker.sock:ro
  - /opt/pwn.college/dojo_plugin:/opt/CTFd/CTFd/plugins/dojo_plugin:ro

x-ctfd-depends: &ctfd-depends
  pgbouncer:
    condition: service_started
  cache:
    condition: service_started

services:
  splunk:
    container_name: splunk
    profiles:
      - splunk
    restart: always
    image: splunk/splunk:9.1.2
    hostname: splunk
    environment:
      - SPLUNK_START_ARGS=--accept-license
      - SPLUNK_PASSWORD=DojoSplunk2024!
      - SPLUNK_HEC_TOKEN=11111111-1111-1111-1111-111111111111
    ports:
      - "8001:8000" # Splunk Web (changed from 8000 to avoid conflict with CTFd)
      - "8088:8088" # HEC
      - "8089:8089" # Splunk management
    volumes:
      - /data/splunk/etc:/opt/splunk/etc
      - /data/splunk/var:/opt/splunk/var
      - /opt/pwn.college/splunk/default.yml:/tmp/defaults/default.yml:ro
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000"]
      interval: 30s
      timeout: 10s
      retries: 3

  workspace-builder:
    container_name: workspace-builder
    hostname: workspace-builder
    profiles:
      - workspace
    build: ./workspace
    environment:
      - DOJO_WORKSPACE=${DOJO_WORKSPACE}
      - NIX_GARBAGE_COLLECT=${NIX_GARBAGE_COLLECT:-false}
    volumes:
      - /data/workspace/nix:/nix

  dojofs:
    container_name: dojofs
    hostname: dojofs
    profiles:
      - workspace
    restart: always
    privileged: true
    pid: host
    build: ./dojofs
    volumes:
      - /run/dojo:/run/dojo:shared
      - /var/run/docker.sock:/var/run/docker.sock:ro

  homefs:
    container_name: homefs
    hostname: homefs
    profiles:
      - main
      - workspace
    restart: always
    privileged: true
    build: ./homefs
    environment:
      - STORAGE_ROOT=/run/homefs
      - STORAGE_HOST=192.168.42.1
    volumes:
      - /run/homefs:/run/homefs:shared
      - /var/run/docker/plugins:/var/run/docker/plugins
    ports:
      - "4201:4201"

  ctfd:
    <<: *ctfd-base
    container_name: ctfd
    profiles:
      - main
    restart: always
    hostname: ctfd
    command:
      - /bin/sh
      - -c
      - |
        if [ "$DOJO_ENV" = "development" ]; then
          FLASK_DEBUG=True WERKZEUG_DEBUG_PIN=off flask run --host 0.0.0.0 --port 8000;
        elif [ "$DOJO_ENV" = "coverage" ]; then
          FLASK_DEBUG=True WERKZEUG_DEBUG_PIN=off exec coverage run --source=CTFd/plugins/dojo_plugin -m flask run --no-reload --host 0.0.0.0 --port 8000;
        elif [ "$DOJO_ENV" = "production" ]; then
          RUN_ID=$(openssl rand -hex 4) ./docker-entrypoint.sh;
        else
          echo "Failed to start ctfd - environment variable DOJO_ENV has invalid value \"$DOJO_ENV\""
        fi
    ulimits:
      nofile:
        soft: 32768
        hard: 1048576
    environment:
      <<: *ctfd-env
      UPLOAD_FOLDER: /var/uploads
      WORKERS: 8
      LOG_FOLDER: /var/log/CTFd
      ACCESS_LOG: "-"
      ERROR_LOG: "-"
      REVERSE_PROXY: "true"
      SERVER_SENT_EVENTS: "false"
      SECRET_KEY: ${SECRET_KEY}
      DOJO_ENV: ${DOJO_ENV}
      CORS_ORIGINS: ${CORS_ORIGINS:-http://future.${DOJO_HOST}}
      DOCKER_USERNAME: ${DOCKER_USERNAME}
      DOCKER_TOKEN: ${DOCKER_TOKEN}
    volumes:
      - /data/CTFd/logs:/var/log/CTFd
      - /data/CTFd/uploads:/var/uploads
      - /data/mac:/var/mac
      - /data/homes:/var/homes:shared
      - /data/dojos:/var/dojos
      - /data/ctfd-ipython:/root/.ipython
      - ./data/coverage:/var/coverage
      - /data/workspace_nodes.json:/var/workspace_nodes.json:ro
      - /data/ssh_host_keys/ssh_known_hosts:/etc/ssh/ssh_known_hosts:ro
      - ./user_firewall.allowed:/var/user_firewall.allowed:ro
      - /etc/docker/seccomp.json:/etc/docker/seccomp.json:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /opt/pwn.college/dojo_plugin:/opt/CTFd/CTFd/plugins/dojo_plugin:ro
      - /opt/pwn.college/dojo_theme:/opt/CTFd/CTFd/themes/dojo_theme:ro
    healthcheck:
      test:
        - "CMD"
        - "python"
        - "-c"
        - |
          import requests
          response = requests.get('http://localhost:8000')
          response.raise_for_status()
      interval: 10s
      timeout: 10s
      retries: 3
    depends_on:
      <<: *ctfd-depends

  db:
    container_name: db
    hostname: db
    profiles:
      - main
    restart: always
    image: postgres:17.5
    environment:
      - POSTGRES_USER=${DB_USER}
      - POSTGRES_PASSWORD=${DB_PASS}
      - POSTGRES_DB=${DB_NAME}
      - PGUSER=${DB_USER}
    volumes:
      - /data/postgres:/var/lib/postgresql/data
      - ./db/init:/docker-entrypoint-initdb.d:ro
    healthcheck:
      test: ["CMD", "pg_isready"]
      interval: 10s
      timeout: 10s
      retries: 3

  pgbouncer:
    container_name: pgbouncer
    hostname: pgbouncer
    profiles:
      - main
    restart: always
    image: edoburu/pgbouncer
    environment:
      DATABASE_URL: postgresql://${DB_USER}:${DB_PASS}@${DB_HOST}/${DB_NAME}
      AUTH_TYPE: scram-sha-256
      POOL_MODE: transaction
      MAX_CLIENT_CONN: 10000
      DEFAULT_POOL_SIZE: 20
    depends_on:
      db:
        condition: service_started

  cache:
    container_name: cache
    hostname: cache
    profiles:
      - main
    restart: always
    image: redis:8
    volumes:
      - /data/redis:/data

  stats-worker:
    <<: *ctfd-base
    container_name: stats-worker
    hostname: stats-worker
    profiles:
      - main
    restart: always
    command: ["flask", "shell", "/opt/CTFd/CTFd/plugins/dojo_plugin/worker/__main__.py"]
    environment:
      <<: *ctfd-env
    volumes: *ctfd-volumes
    depends_on:
      <<: *ctfd-depends

  image-pull-worker:
    <<: *ctfd-base
    container_name: image-pull-worker
    hostname: image-pull-worker
    profiles:
      - main
    restart: always
    command: ["flask", "shell", "/opt/CTFd/CTFd/plugins/dojo_plugin/worker/image_pulls_main.py"]
    environment:
      <<: *ctfd-env
    volumes: *ctfd-volumes
    depends_on:
      <<: *ctfd-depends

  sshd:
    container_name: sshd
    hostname: sshd
    profiles:
      - main
    restart: always
    build: ./sshd
    volumes:
      - /data/workspace_nodes.json:/var/workspace_nodes.json:ro
      - /data/ssh_host_keys:/etc/ssh:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /data/mac:/var/mac:ro
    environment:
      - DATABASE_URL=postgresql+psycopg2://${DB_USER}:${DB_PASS}@pgbouncer:5432/${DB_NAME}
      - REDIS_URL=redis://cache:6379
      - MAC_HOSTNAME=${MAC_HOSTNAME}
      - MAC_USERNAME=${MAC_USERNAME}
      - SSH_PIPER_ENABLED=${SSH_PIPER_ENABLED}
      - SSH_PIPER_API_TOKEN=${SSH_PIPER_API_TOKEN}
      - SSH_PIPER_PROVISION_ENDPOINT=http://ctfd:8000/pwncollege_api/v1/ssh_auto_account
      - SSH_PIPER_UPSTREAM_HOST=${SSH_PIPER_UPSTREAM_HOST}
      - SSH_PIPER_UPSTREAM_PORT=${SSH_PIPER_UPSTREAM_PORT}
      - SSH_PIPER_UPSTREAM_USER=${SSH_PIPER_UPSTREAM_USER}
    ports:
      - "22:22"
    depends_on:
      pgbouncer:
        condition: service_started
      cache:
        condition: service_started

  nginx:
    container_name: nginx
    hostname: nginx
    profiles:
      - main
    restart: always
    build: ./nginx
    ports:
      - "80:80"
      - "443:443"
    environment:
      - DOJO_HOST=${DOJO_HOST}
      - DOJO_ENV=${DOJO_ENV}
      - WORKSPACE_HOST=${WORKSPACE_HOST}
      - WORKSPACE_SECRET=${WORKSPACE_SECRET}
    volumes:
      - /data/acme:/var/cache/nginx/acme-letsencrypt
    networks:
      default:
      workspace_net:
        aliases:
          - nginx
        ipv4_address: 10.0.0.3

  nginx-workspace:
    container_name: nginx-workspace
    hostname: nginx-workspace
    profiles:
      - workspace_exclusive
    restart: always
    build: ./nginx-workspace
    ports:
      - "80:80"
      - "443:443"
      - "8888:8888"
    environment:
      - DOJO_ENV=${DOJO_ENV}
      - WORKSPACE_HOST=${WORKSPACE_HOST}
      - WORKSPACE_SECRET=${WORKSPACE_SECRET}
    volumes:
      - /data/acme:/var/cache/nginx/acme-letsencrypt
    networks:
      default:
        aliases:
          - ${WORKSPACE_HOST}
      workspace_net:
        aliases:
          - nginx
        ipv4_address: 10.0.0.3

  node-exporter:
    container_name: node-exporter
    hostname: node-exporter
    profiles:
      - main
      - workspace
    restart: always
    image: prom/node-exporter
    command:
      - "--path.rootfs=/host"
    network_mode: host
    pid: host
    volumes:
      - /:/host:ro,rslave

  cadvisor:
    container_name: cadvisor
    hostname: cadvisor
    profiles:
      - main
      - workspace
    restart: always
    image: gcr.io/cadvisor/cadvisor
    privileged: true
    ports:
      - "8080:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /data/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro

  prometheus:
    container_name: prometheus
    hostname: prometheus
    profiles:
      - main
    restart: always
    image: prom/prometheus
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_targets:/etc/prometheus/targets:ro
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:9090/-/healthy"]
      interval: 10s
      timeout: 10s
      retries: 3
    depends_on:
      prometheus-generate-targets:
        condition: service_completed_successfully

  prometheus-generate-targets:
    image: python:3.12-slim
    profiles:
      - main
    command:
      - /usr/local/bin/python
      - -c
      - |
        import json
        main_node_ip = "192.168.42.1"
        workspace_nodes = json.load(open("/var/workspace_nodes.json"))
        workspace_node_ips = [f"192.168.42.{int(node_id) + 1}" for node_id in workspace_nodes]
        cadvisor_targets = [{
            "labels": {"job": "cadvisor"},
            "targets": [f"{ip}:8080" for ip in [main_node_ip] + workspace_node_ips]
        }]
        node_exporter_targets = [{
            "labels": {"job": "node_exporter"},
            "targets": [f"{ip}:9100" for ip in [main_node_ip] + workspace_node_ips]
        }]
        with open("/etc/prometheus/targets/cadvisor.json", "w") as f:
            json.dump(cadvisor_targets, f, indent=2)
        with open("/etc/prometheus/targets/node_exporter.json", "w") as f:
            json.dump(node_exporter_targets, f, indent=2)
    volumes:
      - /data/workspace_nodes.json:/var/workspace_nodes.json:ro
      - prometheus_targets:/etc/prometheus/targets

  frontend:
    container_name: frontend
    profiles:
      - main
    restart: always
    build:
      context: ./frontend
      dockerfile: Dockerfile
      args:
        - NEXT_PUBLIC_DOJO_HOST=${DOJO_HOST}
        - NEXT_PUBLIC_DOJO_ENV=${DOJO_ENV}
    user: root
    ports:
      - "3000"
    environment:
      - NEXT_PUBLIC_DOJO_HOST=${DOJO_HOST}
      - NEXT_PUBLIC_DOJO_ENV=${DOJO_ENV}
      - NODE_ENV=${DOJO_ENV}
      - PORT=3000
      - HOSTNAME=0.0.0.0
    command:
      - /bin/sh
      - -c
      - |
        if [ "$DOJO_ENV" = "production" ]; then
          exec bun ./server.js
        else
          cd /opt/pwn.college/frontend
          if [ ! -x node_modules/.bin/next ]; then
            bun install
          fi
          exec bun dev --turbo
        fi
    volumes:
      - /opt/pwn.college/frontend:/opt/pwn.college/frontend

  grafana:
    container_name: grafana
    hostname: grafana
    profiles:
      - main
    restart: always
    image: grafana/grafana
    ports:
      - "3000:3000"
    environment:
      GF_SECURITY_DISABLE_INITIAL_ADMIN_CREATION: "true"
      GF_AUTH_ANONYMOUS_ENABLED: "true"
      GF_AUTH_ANONYMOUS_ORG_ROLE: "Admin"
      GF_AUTH_DISABLE_SIGNOUT_MENU: "true"
      GF_AUTH_DISABLE_LOGIN_FORM: "true"
    volumes:
      - ./grafana/datasource.yml:/etc/grafana/provisioning/datasources/datasource.yml:ro
    depends_on:
      prometheus:
        condition: service_healthy

  watchdog:
    container_name: watchdog
    hostname: watchdog
    profiles:
      - main
    restart: always
    build: ./watchdog
    volumes:
      - /data/workspace_nodes.json:/var/workspace_nodes.json:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro

  create-workspace-net:
    profiles:
      - main
      - workspace
    image: busybox:uclibc
    command: /bin/true
    networks:
      - workspace_net

volumes:
  prometheus_targets:

networks:
  default:
    driver: bridge
  workspace_net:
    name: workspace_net
    driver: bridge
    ipam:
      config:
        - subnet: 10.0.0.0/8
    driver_opts:
      com.docker.network.bridge.name: "workspace_net"
